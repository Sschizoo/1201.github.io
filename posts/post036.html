<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building a Real-Time Analytics Dashboard: WebSockets, Redis, and React - 我的博客</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1 class="slogan">记录思考，分享生活</h1>
    </header>
    
    <main>
        <div class="container">
            <a href="../index.html" class="back-link">← 返回首页</a>
            
            <article class="article-page">
                <div class="article-header">
                    <h1>Building a Real-Time Analytics Dashboard: WebSockets, Redis, and React</h1>
                    <p class="article-date">2024年05月28日</p>
                </div>
                
                <div class="article-content">
                    <hr />
<p>title: "Building a Real-Time Analytics Dashboard: WebSockets, Redis, and React"<br />
date: "2024-05-28"<br />
tags: ["real-time", "analytics", "websockets", "redis", "react"]</p>
<hr />
<h1>Building a Real-Time Analytics Dashboard: WebSockets, Redis, and React</h1>
<p>Last quarter, our product team requested a real-time analytics dashboard to monitor user behavior, system performance, and business metrics. The challenge was to handle thousands of concurrent users while providing sub-second data updates. This project became a fascinating exploration of real-time systems architecture, and I'd like to share the journey and technical decisions we made.</p>
<h2>Project Requirements</h2>
<p>The dashboard needed to display:<br />
- Real-time user activity (logins, purchases, page views)<br />
- System metrics (CPU, memory, response times)<br />
- Business KPIs (revenue, conversion rates, active users)<br />
- Geographic distribution of users<br />
- Error rates and system alerts</p>
<p>Requirements:<br />
- Support 1000+ concurrent dashboard users<br />
- Sub-second data updates<br />
- Historical data capability<br />
- Scalable architecture<br />
- Mobile-responsive interface</p>
<h2>Architecture Overview</h2>
<p>We designed a multi-tier architecture:</p>
<pre><code class="language-javascript">// System architecture components
const systemArchitecture = {
  dataIngestion: {
    eventCollectors: ['User events', 'System metrics', 'Business events'],
    ingestionRate: '10,000+ events/second',
    protocols: ['HTTP', 'WebSocket', 'UDP']
  },

  dataProcessing: {
    realTimeProcessor: 'Redis Streams',
    batchProcessor: 'Apache Kafka + Node.js workers',
    aggregationWindows: ['1s', '1m', '5m', '1h', '1d']
  },

  dataStorage: {
    realTime: 'Redis (in-memory)',
    historical: 'InfluxDB (time-series)',
    metadata: 'PostgreSQL'
  },

  apiLayer: {
    realTimeAPI: 'WebSocket server',
    restAPI: 'Express.js',
    caching: 'Redis'
  },

  frontend: {
    framework: 'React + TypeScript',
    stateManagement: 'Redux Toolkit',
    charting: 'D3.js + Chart.js',
    realTimeUpdates: 'WebSocket client'
  }
};
</code></pre>
<h2>Real-Time Data Processing</h2>
<h3>Event Collection System</h3>
<p>First, we built a robust event collection system:</p>
<pre><code class="language-javascript">// event-collector.js
class EventCollector {
  constructor(options = {}) {
    this.redis = new Redis(options.redisUrl);
    this.rateLimiter = new RateLimiter({
      tokensPerInterval: 1000,
      interval: 'second'
    });
    this.eventValidators = new Map();
    this.setupEventValidators();
  }

  setupEventValidators() {
    this.eventValidators.set('user_login', this.validateUserEvent);
    this.eventValidators.set('page_view', this.validatePageViewEvent);
    this.eventValidators.set('purchase', this.validatePurchaseEvent);
    this.eventValidators.set('system_metric', this.validateSystemMetric);
  }

  async collectEvent(eventData) {
    try {
      // Rate limiting
      const rateLimitResult = await this.rateLimiter.checkLimit(eventData.source);
      if (!rateLimitResult.allowed) {
        throw new Error('Rate limit exceeded');
      }

      // Validate event
      const validator = this.eventValidators.get(eventData.type);
      if (validator &amp;&amp; !validator(eventData)) {
        throw new Error('Invalid event data');
      }

      // Enrich event with metadata
      const enrichedEvent = this.enrichEvent(eventData);

      // Store in Redis stream
      await this.storeEvent(enrichedEvent);

      // Trigger real-time processing
      await this.triggerRealTimeProcessing(enrichedEvent);

      return { success: true, eventId: enrichedEvent.id };
    } catch (error) {
      console.error('Event collection error:', error);
      return { success: false, error: error.message };
    }
  }

  enrichEvent(eventData) {
    return {
      ...eventData,
      id: this.generateEventId(),
      timestamp: Date.now(),
      serverTimestamp: new Date().toISOString(),
      sessionId: eventData.sessionId || this.generateSessionId(),
      enrichedAt: Date.now()
    };
  }

  async storeEvent(event) {
    const streamKey = `events:${event.type}`;

    await this.redis.xadd(
      streamKey,
      '*',
      'data', JSON.stringify(event),
      'timestamp', event.timestamp
    );

    // Set TTL for stream entries (keep for 24 hours)
    await this.redis.expire(streamKey, 86400);
  }

  async triggerRealTimeProcessing(event) {
    // Publish to processing channels
    const channels = this.getProcessingChannels(event.type);

    for (const channel of channels) {
      await this.redis.publish(channel, JSON.stringify(event));
    }
  }

  getProcessingChannels(eventType) {
    const channelMap = {
      'user_login': ['user_activity', 'geography', 'real_time_stats'],
      'page_view': ['page_analytics', 'user_journey', 'real_time_stats'],
      'purchase': ['revenue_tracking', 'conversion_analytics', 'real_time_stats'],
      'system_metric': ['system_monitoring', 'alerting']
    };

    return channelMap[eventType] || ['general_analytics'];
  }

  validateUserEvent(event) {
    return event.userId &amp;&amp; event.action &amp;&amp; typeof event.userId === 'string';
  }

  validatePageViewEvent(event) {
    return event.page &amp;&amp; event.referrer !== undefined &amp;&amp; event.sessionId;
  }

  validatePurchaseEvent(event) {
    return event.amount &amp;&amp; event.currency &amp;&amp; event.userId &amp;&amp; event.productId;
  }

  validateSystemMetric(event) {
    return event.metricName &amp;&amp; event.value !== undefined &amp;&amp; event.host;
  }
}
</code></pre>
<h3>Real-Time Aggregation Engine</h3>
<p>We built an aggregation engine to process events in real-time:</p>
<pre><code class="language-javascript">// real-time-aggregator.js
class RealTimeAggregator {
  constructor(options = {}) {
    this.redis = new Redis(options.redisUrl);
    this.aggregationWindows = ['1s', '1m', '5m', '1h'];
    this.processors = new Map();
    this.setupProcessors();
  }

  setupProcessors() {
    this.processors.set('user_activity', new UserActivityProcessor(this.redis));
    this.processors.set('revenue_tracking', new RevenueProcessor(this.redis));
    this.processors.set('system_monitoring', new SystemMetricsProcessor(this.redis));
    this.processors.set('geography', new GeographyProcessor(this.redis));
  }

  async startProcessing() {
    // Subscribe to processing channels
    for (const [channel, processor] of this.processors) {
      this.redis.subscribe(channel);
    }

    this.redis.on('message', (channel, message) =&gt; {
      this.processEvent(channel, JSON.parse(message));
    });
  }

  async processEvent(channel, event) {
    const processor = this.processors.get(channel);
    if (!processor) return;

    try {
      await processor.process(event);

      // Update aggregations for all time windows
      await this.updateAggregations(channel, event);

    } catch (error) {
      console.error(`Error processing event in ${channel}:`, error);
    }
  }

  async updateAggregations(channel, event) {
    const now = Date.now();

    for (const window of this.aggregationWindows) {
      const windowStart = this.getWindowStart(now, window);
      const key = `agg:${channel}:${window}:${windowStart}`;

      await this.updateAggregationKey(key, event, window);
    }
  }

  async updateAggregationKey(key, event, window) {
    const pipeline = this.redis.pipeline();

    // Increment counters
    pipeline.hincrby(key, 'count', 1);

    // Update specific metrics based on event type
    if (event.type === 'purchase') {
      pipeline.hincrbyfloat(key, 'revenue', parseFloat(event.amount));
    }

    if (event.type === 'page_view') {
      pipeline.hincrbyfloat(key, 'page_views', 1);
    }

    // Set expiration
    const ttl = this.getWindowTTL(window);
    pipeline.expire(key, ttl);

    await pipeline.exec();
  }

  getWindowStart(timestamp, window) {
    const windowMs = this.parseWindow(window);
    return Math.floor(timestamp / windowMs) * windowMs;
  }

  parseWindow(window) {
    const unit = window.slice(-1);
    const value = parseInt(window.slice(0, -1));

    const multipliers = { s: 1000, m: 60000, h: 3600000, d: 86400000 };
    return value * multipliers[unit];
  }

  getWindowTTL(window) {
    const windowMs = this.parseWindow(window);
    return Math.ceil(windowMs / 1000) * 10; // Keep for 10 window periods
  }
}

// Specialized processors
class UserActivityProcessor {
  constructor(redis) {
    this.redis = redis;
  }

  async process(event) {
    const key = `user_activity:${event.userId}`;

    await this.redis.pipeline()
      .hset(key, {
        lastSeen: event.timestamp,
        lastAction: event.action,
        sessionId: event.sessionId
      })
      .expire(key, 3600) // 1 hour TTL
      .exec();

    // Update active users count
    await this.updateActiveUsers(event);
  }

  async updateActiveUsers(event) {
    const now = Date.now();
    const activeUsersKey = 'active_users';

    // Add user to active set with score as timestamp
    await this.redis.zadd(activeUsersKey, now, event.userId);

    // Remove users inactive for more than 30 minutes
    const cutoff = now - (30 * 60 * 1000);
    await this.redis.zremrangebyscore(activeUsersKey, 0, cutoff);
  }
}

class RevenueProcessor {
  constructor(redis) {
    this.redis = redis;
  }

  async process(event) {
    if (event.type !== 'purchase') return;

    const todayKey = `revenue:${this.getDateKey(new Date())}`;
    const monthKey = `revenue:${this.getMonthKey(new Date())}`;

    await this.redis.pipeline()
      .hincrbyfloat(todayKey, 'total', parseFloat(event.amount))
      .hincrby(todayKey, 'count', 1)
      .hincrbyfloat(monthKey, 'total', parseFloat(event.amount))
      .hincrby(monthKey, 'count', 1)
      .expire(todayKey, 86400 * 7) // Keep for 7 days
      .expire(monthKey, 86400 * 365) // Keep for 1 year
      .exec();

    // Update conversion funnel
    await this.updateConversionFunnel(event);
  }

  async updateConversionFunnel(event) {
    const funnelKey = `funnel:${this.getDateKey(new Date())}`;

    await this.redis.hincrby(funnelKey, 'purchases', 1);
    await this.redis.expire(funnelKey, 86400 * 7);
  }

  getDateKey(date) {
    return date.toISOString().split('T')[0];
  }

  getMonthKey(date) {
    return `${date.getFullYear()}-${String(date.getMonth() + 1).padStart(2, '0')}`;
  }
}
</code></pre>
<h2>WebSocket Server Implementation</h2>
<h3>Real-Time Data Broadcasting</h3>
<pre><code class="language-javascript">// websocket-server.js
const WebSocket = require('ws');
const Redis = require('ioredis');

class AnalyticsWebSocketServer {
  constructor(options = {}) {
    this.port = options.port || 8080;
    this.redis = new Redis(options.redisUrl);
    this.clients = new Map();
    this.subscriptions = new Map();
    this.broadcastInterval = options.broadcastInterval || 1000; // 1 second

    this.setupServer();
    this.setupRedisSubscriptions();
    this.startBroadcasting();
  }

  setupServer() {
    this.wss = new WebSocket.Server({ 
      port: this.port,
      perMessageDeflate: {
        zlibDeflateOptions: {
          threshold: 1024,
          concurrencyLimit: 10,
        },
      }
    });

    this.wss.on('connection', (ws, req) =&gt; {
      this.handleConnection(ws, req);
    });

    console.log(`WebSocket server listening on port ${this.port}`);
  }

  handleConnection(ws, req) {
    const clientId = this.generateClientId();
    const clientInfo = {
      id: clientId,
      ws: ws,
      subscriptions: new Set(),
      lastPing: Date.now(),
      userAgent: req.headers['user-agent'],
      ip: req.socket.remoteAddress
    };

    this.clients.set(clientId, clientInfo);

    ws.on('message', (message) =&gt; {
      this.handleMessage(clientId, message);
    });

    ws.on('close', () =&gt; {
      this.handleDisconnection(clientId);
    });

    ws.on('pong', () =&gt; {
      if (this.clients.has(clientId)) {
        this.clients.get(clientId).lastPing = Date.now();
      }
    });

    // Send initial connection success message
    this.sendToClient(clientId, {
      type: 'connection_established',
      clientId: clientId,
      timestamp: Date.now()
    });
  }

  handleMessage(clientId, message) {
    try {
      const data = JSON.parse(message);

      switch (data.type) {
        case 'subscribe':
          this.handleSubscription(clientId, data.channels);
          break;
        case 'unsubscribe':
          this.handleUnsubscription(clientId, data.channels);
          break;
        case 'ping':
          this.sendToClient(clientId, { type: 'pong', timestamp: Date.now() });
          break;
        default:
          console.warn(`Unknown message type: ${data.type}`);
      }
    } catch (error) {
      console.error('Error handling message:', error);
      this.sendToClient(clientId, {
        type: 'error',
        message: 'Invalid message format'
      });
    }
  }

  handleSubscription(clientId, channels) {
    const client = this.clients.get(clientId);
    if (!client) return;

    channels.forEach(channel =&gt; {
      client.subscriptions.add(channel);

      if (!this.subscriptions.has(channel)) {
        this.subscriptions.set(channel, new Set());
      }
      this.subscriptions.get(channel).add(clientId);
    });

    this.sendToClient(clientId, {
      type: 'subscription_confirmed',
      channels: Array.from(client.subscriptions)
    });
  }

  handleUnsubscription(clientId, channels) {
    const client = this.clients.get(clientId);
    if (!client) return;

    channels.forEach(channel =&gt; {
      client.subscriptions.delete(channel);

      if (this.subscriptions.has(channel)) {
        this.subscriptions.get(channel).delete(clientId);

        if (this.subscriptions.get(channel).size === 0) {
          this.subscriptions.delete(channel);
        }
      }
    });
  }

  handleDisconnection(clientId) {
    const client = this.clients.get(clientId);
    if (!client) return;

    // Remove from all subscriptions
    client.subscriptions.forEach(channel =&gt; {
      if (this.subscriptions.has(channel)) {
        this.subscriptions.get(channel).delete(clientId);

        if (this.subscriptions.get(channel).size === 0) {
          this.subscriptions.delete(channel);
        }
      }
    });

    this.clients.delete(clientId);
    console.log(`Client ${clientId} disconnected`);
  }

  setupRedisSubscriptions() {
    // Subscribe to aggregated data updates
    this.redis.subscribe('analytics_updates');

    this.redis.on('message', (channel, message) =&gt; {
      if (channel === 'analytics_updates') {
        this.broadcastUpdate(JSON.parse(message));
      }
    });
  }

  startBroadcasting() {
    setInterval(() =&gt; {
      this.broadcastCurrentMetrics();
      this.checkClientHealth();
    }, this.broadcastInterval);
  }

  async broadcastCurrentMetrics() {
    try {
      const metrics = await this.getCurrentMetrics();

      // Broadcast to all subscribed clients
      for (const [channel, data] of Object.entries(metrics)) {
        this.broadcastToChannel(channel, {
          type: 'metrics_update',
          channel: channel,
          data: data,
          timestamp: Date.now()
        });
      }
    } catch (error) {
      console.error('Error broadcasting metrics:', error);
    }
  }

  async getCurrentMetrics() {
    const now = Date.now();
    const windowStart = Math.floor(now / 1000) * 1000; // 1-second window

    const metrics = {};

    // Real-time user activity
    const activeUsersCount = await this.redis.zcard('active_users');
    metrics.user_activity = {
      activeUsers: activeUsersCount,
      timestamp: windowStart
    };

    // Revenue metrics
    const revenueKey = `agg:revenue_tracking:1s:${windowStart}`;
    const revenueData = await this.redis.hgetall(revenueKey);
    metrics.revenue = {
      totalRevenue: parseFloat(revenueData.revenue || 0),
      transactionCount: parseInt(revenueData.count || 0),
      timestamp: windowStart
    };

    // System metrics
    const systemMetrics = await this.getSystemMetrics();
    metrics.system = systemMetrics;

    return metrics;
  }

  async getSystemMetrics() {
    // Get latest system metrics from Redis
    const cpuUsage = await this.redis.get('system:cpu_usage');
    const memoryUsage = await this.redis.get('system:memory_usage');
    const responseTime = await this.redis.get('system:avg_response_time');

    return {
      cpuUsage: parseFloat(cpuUsage || 0),
      memoryUsage: parseFloat(memoryUsage || 0),
      responseTime: parseFloat(responseTime || 0),
      timestamp: Date.now()
    };
  }

  broadcastToChannel(channel, message) {
    const subscribers = this.subscriptions.get(channel);
    if (!subscribers || subscribers.size === 0) return;

    const messageStr = JSON.stringify(message);

    subscribers.forEach(clientId =&gt; {
      this.sendToClient(clientId, message);
    });
  }

  sendToClient(clientId, message) {
    const client = this.clients.get(clientId);
    if (!client || client.ws.readyState !== WebSocket.OPEN) return;

    try {
      client.ws.send(JSON.stringify(message));
    } catch (error) {
      console.error(`Error sending message to client ${clientId}:`, error);
      this.handleDisconnection(clientId);
    }
  }

  checkClientHealth() {
    const now = Date.now();
    const timeout = 60000; // 1 minute timeout

    for (const [clientId, client] of this.clients) {
      if (now - client.lastPing &gt; timeout) {
        console.log(`Client ${clientId} timed out`);
        client.ws.terminate();
        this.handleDisconnection(clientId);
      } else {
        // Send ping
        client.ws.ping();
      }
    }
  }

  broadcastUpdate(update) {
    this.broadcastToChannel(update.channel, {
      type: 'real_time_update',
      data: update.data,
      timestamp: update.timestamp
    });
  }

  generateClientId() {
    return `client_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  getStats() {
    return {
      connectedClients: this.clients.size,
      activeSubscriptions: this.subscriptions.size,
      totalSubscriptionCount: Array.from(this.subscriptions.values())
        .reduce((sum, subs) =&gt; sum + subs.size, 0)
    };
  }
}
</code></pre>
<h2>React Dashboard Implementation</h2>
<h3>Real-Time Data Visualization</h3>
<pre><code class="language-typescript">// Dashboard.tsx
import React, { useState, useEffect, useCallback, useMemo } from 'react';
import { useWebSocket } from './hooks/useWebSocket';
import { MetricsChart } from './components/MetricsChart';
import { UserActivityWidget } from './components/UserActivityWidget';
import { RevenueWidget } from './components/RevenueWidget';
import { SystemHealthWidget } from './components/SystemHealthWidget';

interface DashboardProps {
  websocketUrl: string;
}

interface MetricsData {
  user_activity: {
    activeUsers: number;
    timestamp: number;
  };
  revenue: {
    totalRevenue: number;
    transactionCount: number;
    timestamp: number;
  };
  system: {
    cpuUsage: number;
    memoryUsage: number;
    responseTime: number;
    timestamp: number;
  };
}

const Dashboard: React.FC&lt;DashboardProps&gt; = ({ websocketUrl }) =&gt; {
  const [metrics, setMetrics] = useState&lt;MetricsData | null&gt;(null);
  const [historicalData, setHistoricalData] = useState&lt;any[]&gt;([]);
  const [connectionStatus, setConnectionStatus] = useState&lt;'connecting' | 'connected' | 'disconnected'&gt;('connecting');

  const { sendMessage, lastMessage, connectionState } = useWebSocket(websocketUrl, {
    onOpen: () =&gt; setConnectionStatus('connected'),
    onClose: () =&gt; setConnectionStatus('disconnected'),
    onError: (error) =&gt; console.error('WebSocket error:', error),
    shouldReconnect: () =&gt; true,
    reconnectAttempts: 10,
    reconnectInterval: 3000
  });

  // Subscribe to channels on connection
  useEffect(() =&gt; {
    if (connectionState === 'connected') {
      sendMessage({
        type: 'subscribe',
        channels: ['user_activity', 'revenue', 'system']
      });
    }
  }, [connectionState, sendMessage]);

  // Handle incoming messages
  useEffect(() =&gt; {
    if (lastMessage?.data) {
      try {
        const message = JSON.parse(lastMessage.data);

        switch (message.type) {
          case 'metrics_update':
            handleMetricsUpdate(message);
            break;
          case 'real_time_update':
            handleRealTimeUpdate(message);
            break;
          case 'connection_established':
            console.log('Connection established:', message.clientId);
            break;
          default:
            console.log('Unknown message type:', message.type);
        }
      } catch (error) {
        console.error('Error parsing message:', error);
      }
    }
  }, [lastMessage]);

  const handleMetricsUpdate = useCallback((message: any) =&gt; {
    setMetrics(prevMetrics =&gt; ({
      ...prevMetrics,
      [message.channel]: message.data
    }));

    // Add to historical data
    setHistoricalData(prevData =&gt; {
      const newData = [...prevData, {
        timestamp: message.timestamp,
        channel: message.channel,
        data: message.data
      }];

      // Keep only last 100 data points
      return newData.slice(-100);
    });
  }, []);

  const handleRealTimeUpdate = useCallback((message: any) =&gt; {
    // Handle real-time updates (alerts, notifications, etc.)
    console.log('Real-time update:', message);
  }, []);

  const chartData = useMemo(() =&gt; {
    if (!historicalData.length) return {};

    const groupedData: { [key: string]: any[] } = {};

    historicalData.forEach(item =&gt; {
      if (!groupedData[item.channel]) {
        groupedData[item.channel] = [];
      }
      groupedData[item.channel].push({
        timestamp: item.timestamp,
        ...item.data
      });
    });

    return groupedData;
  }, [historicalData]);

  const renderConnectionStatus = () =&gt; {
    const statusColors = {
      connecting: 'yellow',
      connected: 'green',
      disconnected: 'red'
    };

    return (
      &lt;div className=&quot;connection-status&quot;&gt;
        &lt;span 
          className={`status-indicator ${connectionStatus}`}
          style={{ backgroundColor: statusColors[connectionStatus] }}
        /&gt;
        {connectionStatus.toUpperCase()}
      &lt;/div&gt;
    );
  };

  if (!metrics) {
    return (
      &lt;div className=&quot;dashboard-loading&quot;&gt;
        &lt;div className=&quot;loading-spinner&quot; /&gt;
        &lt;p&gt;Connecting to real-time data...&lt;/p&gt;
        {renderConnectionStatus()}
      &lt;/div&gt;
    );
  }

  return (
    &lt;div className=&quot;dashboard&quot;&gt;
      &lt;header className=&quot;dashboard-header&quot;&gt;
        &lt;h1&gt;Real-Time Analytics Dashboard&lt;/h1&gt;
        {renderConnectionStatus()}
      &lt;/header&gt;

      &lt;div className=&quot;dashboard-grid&quot;&gt;
        &lt;div className=&quot;widget-container&quot;&gt;
          &lt;UserActivityWidget 
            data={metrics.user_activity}
            historicalData={chartData.user_activity || []}
          /&gt;
        &lt;/div&gt;

        &lt;div className=&quot;widget-container&quot;&gt;
          &lt;RevenueWidget 
            data={metrics.revenue}
            historicalData={chartData.revenue || []}
          /&gt;
        &lt;/div&gt;

        &lt;div className=&quot;widget-container&quot;&gt;
          &lt;SystemHealthWidget 
            data={metrics.system}
            historicalData={chartData.system || []}
          /&gt;
        &lt;/div&gt;

        &lt;div className=&quot;widget-container full-width&quot;&gt;
          &lt;MetricsChart 
            data={chartData}
            title=&quot;Combined Metrics Overview&quot;
          /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  );
};

export default Dashboard;
</code></pre>
<h3>Custom WebSocket Hook</h3>
<pre><code class="language-typescript">// hooks/useWebSocket.ts
import { useEffect, useRef, useState, useCallback } from 'react';

interface UseWebSocketOptions {
  onOpen?: () =&gt; void;
  onClose?: () =&gt; void;
  onError?: (error: Event) =&gt; void;
  shouldReconnect?: () =&gt; boolean;
  reconnectAttempts?: number;
  reconnectInterval?: number;
}

interface UseWebSocketReturn {
  sendMessage: (message: any) =&gt; void;
  lastMessage: MessageEvent | null;
  connectionState: 'connecting' | 'connected' | 'disconnected';
}

export const useWebSocket = (
  url: string,
  options: UseWebSocketOptions = {}
): UseWebSocketReturn =&gt; {
  const [connectionState, setConnectionState] = useState&lt;'connecting' | 'connected' | 'disconnected'&gt;('connecting');
  const [lastMessage, setLastMessage] = useState&lt;MessageEvent | null&gt;(null);

  const websocketRef = useRef&lt;WebSocket | null&gt;(null);
  const reconnectTimeoutRef = useRef&lt;NodeJS.Timeout | null&gt;(null);
  const reconnectAttemptsRef = useRef(0);
  const messageQueueRef = useRef&lt;any[]&gt;([]);

  const {
    onOpen,
    onClose,
    onError,
    shouldReconnect = () =&gt; true,
    reconnectAttempts = 5,
    reconnectInterval = 3000
  } = options;

  const connect = useCallback(() =&gt; {
    try {
      const ws = new WebSocket(url);

      ws.onopen = () =&gt; {
        setConnectionState('connected');
        reconnectAttemptsRef.current = 0;
        onOpen?.();

        // Send queued messages
        while (messageQueueRef.current.length &gt; 0) {
          const message = messageQueueRef.current.shift();
          ws.send(JSON.stringify(message));
        }
      };

      ws.onclose = () =&gt; {
        setConnectionState('disconnected');
        onClose?.();

        if (shouldReconnect() &amp;&amp; reconnectAttemptsRef.current &lt; reconnectAttempts) {
          reconnectAttemptsRef.current++;
          reconnectTimeoutRef.current = setTimeout(() =&gt; {
            setConnectionState('connecting');
            connect();
          }, reconnectInterval);
        }
      };

      ws.onerror = (error) =&gt; {
        onError?.(error);
      };

      ws.onmessage = (message) =&gt; {
        setLastMessage(message);
      };

      websocketRef.current = ws;
    } catch (error) {
      console.error('WebSocket connection error:', error);
      setConnectionState('disconnected');
    }
  }, [url, onOpen, onClose, onError, shouldReconnect, reconnectAttempts, reconnectInterval]);

  const sendMessage = useCallback((message: any) =&gt; {
    if (websocketRef.current?.readyState === WebSocket.OPEN) {
      websocketRef.current.send(JSON.stringify(message));
    } else {
      // Queue message for when connection is established
      messageQueueRef.current.push(message);
    }
  }, []);

  useEffect(() =&gt; {
    connect();

    return () =&gt; {
      if (reconnectTimeoutRef.current) {
        clearTimeout(reconnectTimeoutRef.current);
      }
      websocketRef.current?.close();
    };
  }, [connect]);

  return {
    sendMessage,
    lastMessage,
    connectionState
  };
};
</code></pre>
<h2>Performance Optimizations</h2>
<h3>Data Compression and Batching</h3>
<pre><code class="language-javascript">// data-compression.js
class DataCompressor {
  constructor() {
    this.compressionThreshold = 1024; // 1KB
  }

  compress(data) {
    const jsonString = JSON.stringify(data);

    if (jsonString.length &lt; this.compressionThreshold) {
      return { compressed: false, data: jsonString };
    }

    // Use gzip compression for larger payloads
    const compressed = zlib.gzipSync(jsonString);

    return {
      compressed: true,
      data: compressed.toString('base64'),
      originalSize: jsonString.length,
      compressedSize: compressed.length
    };
  }

  decompress(compressedData) {
    if (!compressedData.compressed) {
      return JSON.parse(compressedData.data);
    }

    const buffer = Buffer.from(compressedData.data, 'base64');
    const decompressed = zlib.gunzipSync(buffer);
    return JSON.parse(decompressed.toString());
  }
}

// Message batching for high-frequency updates
class MessageBatcher {
  constructor(options = {}) {
    this.batchSize = options.batchSize || 10;
    this.flushInterval = options.flushInterval || 100; // 100ms
    this.batches = new Map();

    setInterval(() =&gt; this.flush(), this.flushInterval);
  }

  addMessage(channel, message) {
    if (!this.batches.has(channel)) {
      this.batches.set(channel, []);
    }

    const batch = this.batches.get(channel);
    batch.push(message);

    if (batch.length &gt;= this.batchSize) {
      this.flushChannel(channel);
    }
  }

  flushChannel(channel) {
    const batch = this.batches.get(channel);
    if (!batch || batch.length === 0) return;

    const batchedMessage = {
      type: 'batched_update',
      channel: channel,
      messages: batch,
      count: batch.length,
      timestamp: Date.now()
    };

    this.sendBatch(batchedMessage);
    this.batches.set(channel, []);
  }

  flush() {
    for (const channel of this.batches.keys()) {
      this.flushChannel(channel);
    }
  }

  sendBatch(batchedMessage) {
    // Override this method to send the batch
    console.log('Sending batch:', batchedMessage);
  }
}
</code></pre>
<h2>Results and Impact</h2>
<p>The real-time analytics dashboard achieved impressive results:</p>
<h3>Performance Metrics</h3>
<ul>
<li><strong>Latency</strong>: Sub-200ms from event to dashboard display</li>
<li><strong>Throughput</strong>: Successfully handled 10,000+ events per second</li>
<li><strong>Concurrent Users</strong>: Supported 1,000+ simultaneous dashboard users</li>
<li><strong>Uptime</strong>: 99.9% availability over 6 months</li>
</ul>
<h3>Business Impact</h3>
<ul>
<li><strong>Decision Speed</strong>: Reduced time to detect and respond to issues by 75%</li>
<li><strong>User Engagement</strong>: Product teams now make data-driven decisions in real-time</li>
<li><strong>Operational Efficiency</strong>: Automated alerting reduced manual monitoring by 60%</li>
</ul>
<p>The implementation utilized advanced spatiotemporal modeling techniques to understand data flow patterns across time zones and user sessions, implemented lightweight engines for specific visualization rendering tasks, and created multi-modal data integration systems that seamlessly handled different types of analytics data from various sources.</p>
<h2>Lessons Learned</h2>
<ol>
<li><strong>Architecture Matters</strong>: Designing for scale from the beginning saved us from major refactoring later</li>
<li><strong>WebSocket Management</strong>: Proper connection management and reconnection logic are crucial for reliability</li>
<li><strong>Data Aggregation</strong>: Pre-aggregating data at different time windows dramatically improved performance</li>
<li><strong>Error Handling</strong>: Comprehensive error handling and monitoring are essential for production systems</li>
<li><strong>User Experience</strong>: Real-time doesn't mean overwhelming—smart data compression and selective updates improve UX</li>
</ol>
<h2>Future Improvements</h2>
<p>Looking ahead, we're planning several enhancements:</p>
<pre><code class="language-javascript">const futureImprovements = {
  scalability: [
    'Implement horizontal scaling with WebSocket clusters',
    'Add support for multiple Redis instances',
    'Introduce message queuing for peak load handling'
  ],
  features: [
    'Custom dashboard builder for different user roles',
    'Advanced alerting and notification system',
    'Historical data analysis and trend prediction',
    'Mobile app with push notifications'
  ],
  performance: [
    'Implement data streaming with Apache Kafka',
    'Add edge caching for global distribution',
    'Optimize frontend rendering with virtual scrolling',
    'Implement progressive data loading'
  ]
};
</code></pre>
<p>This project demonstrated that building real-time systems requires careful consideration of architecture, performance, and user experience. The key is to balance real-time responsiveness with system stability and user needs. The resulting dashboard has become an essential tool for our organization, enabling faster decision-making and better understanding of our users and systems.</p>
                </div>
            </article>
        </div>
    </main>
    
    <footer>
        <p>&copy; 2025 我的博客. All rights reserved.</p>
    </footer>
</body>
</html>